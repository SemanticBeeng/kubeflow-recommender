{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is implementation of the Recommender training\n",
    "\n",
    "This implementation takes a list of users and their purchasing history to calculate prediction\n",
    "on the probability that they would by a certain product.\n",
    "The implementation is structured in 2 parts:\n",
    "1. Build rating matrix based on the purchasing history. The implementation is based on this blog post\n",
    "https://medium.com/datadriveninvestor/how-to-build-a-recommendation-system-for-purchase-data-step-by-step-d6d7a78800b6\n",
    "2. Build collabarative filtering model based on the rating matrix. The implementation is based on this project https://github.com/Piyushdharkar/Collaborative-Filtering-Using-Keras \n",
    "\n",
    "Implementation is leveraging Minio for storing both source data and result models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/07/f7d7ced2f97ca3098c16565efbe6b15fafcba53e8d9bdb431e09140514b0/pip-19.2.2-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 21.3MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.0.1\n",
      "    Uninstalling pip-19.0.1:\n",
      "      Successfully uninstalled pip-19.0.1\n",
      "Successfully installed pip-19.2.2\n",
      "Requirement already up-to-date: pandas in /opt/conda/lib/python3.6/site-packages (0.25.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from pandas) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n",
      "Requirement already up-to-date: keras in /opt/conda/lib/python3.6/site-packages (2.2.4)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.6/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras) (5.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from keras) (1.0.9)\n",
      "Requirement already up-to-date: minio in /opt/conda/lib/python3.6/site-packages (4.0.19)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /opt/conda/lib/python3.6/site-packages (from minio) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: future in /opt/conda/lib/python3.6/site-packages (from minio) (0.17.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in /opt/conda/lib/python3.6/site-packages (from minio) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /opt/conda/lib/python3.6/site-packages (from minio) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /opt/conda/lib/python3.6/site-packages (from minio) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil->minio) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip3 install pandas --upgrade\n",
    "!pip3 install keras --upgrade\n",
    "!pip3 install minio --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from minio import Minio\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read data\n",
    "\n",
    "For reading data we are using two diffierent approaches:\n",
    "1. We use Tensorflow build in support to write resulting model to Minio\n",
    "2. We use Minio APIs to read source data using Pandas. We could of use Boto APIs here instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minio parameters : URL  minio-service.kubeflow.svc.cluster.local:9000  key  minio  secret  minio123\n"
     ]
    }
   ],
   "source": [
    "minio_endpoint = os.environ.get('MINIO_URL', 'minio-service.kubeflow.svc.cluster.local:9000')\n",
    "minio_key = os.environ.get('MINIO_KEY', 'minio')\n",
    "minio_secret = os.environ.get('MINIO_SECRET', 'minio123')\n",
    "\n",
    "print('Minio parameters : URL ', minio_endpoint, ' key ', minio_key, ' secret ', minio_secret)\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = minio_key\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = minio_secret\n",
    "os.environ['AWS_REGION'] = 'us-west-1'\n",
    "os.environ['S3_REGION'] = 'us-west-1'\n",
    "os.environ['S3_ENDPOINT'] = minio_endpoint\n",
    "os.environ['S3_USE_HTTPS'] = '0'\n",
    "os.environ['S3_VERIFY_SSL'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minioClient = Minio(minio_endpoint,\n",
    "                    access_key=minio_key,\n",
    "                    secret_key=minio_secret,\n",
    "                    secure=False)\n",
    "\n",
    "minioClient.fget_object('data', 'recommender/users.csv', '/tmp/users.csv')\n",
    "customers = pd.read_csv('/tmp/users.csv')\n",
    "minioClient.fget_object('data', 'recommender/transactions.csv', '/tmp/transactions.csv')\n",
    "transactions = pd.read_csv('/tmp/transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerId\n",
       "0        1553\n",
       "1       20400\n",
       "2       19750\n",
       "3        6334\n",
       "4       27773"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(customers.shape)\n",
    "customers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62483, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerId</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2|2|23|68|68|111|29|86|107|152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>111|107|29|11|11|11|33|23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>164|227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2|2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerId                        products\n",
       "0           0                              20\n",
       "1           1  2|2|23|68|68|111|29|86|107|152\n",
       "2           2       111|107|29|11|11|11|33|23\n",
       "3           3                         164|227\n",
       "4           5                             2|2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(transactions.shape)\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data preparation\n",
    "\n",
    "Our goal here is to break down each list of items in the products column into rows \n",
    "and count the number of products bought by a user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: split product items\n",
    "transactions['products'] = transactions['products'].apply(lambda x: [int(i) for i in x.split('|')])\n",
    "transactions.head(2).set_index('customerId')['products'].apply(pd.Series).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: organize a given table into a dataframe with customerId, single productId, and purchase count\n",
    "pd.melt(transactions.head(2).set_index('customerId')['products'].apply(pd.Series).reset_index(), \n",
    "             id_vars=['customerId'],\n",
    "             value_name='products') \\\n",
    "    .dropna().drop(['variable'], axis=1) \\\n",
    "    .groupby(['customerId', 'products']) \\\n",
    "    .agg({'products': 'count'}) \\\n",
    "    .rename(columns={'products': 'purchase_count'}) \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns={'products': 'productId'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create data with user, item, and target field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.melt(transactions.set_index('customerId')['products'].apply(pd.Series).reset_index(), \n",
    "             id_vars=['customerId'],\n",
    "             value_name='products') \\\n",
    "    .dropna().drop(['variable'], axis=1) \\\n",
    "    .groupby(['customerId', 'products']) \\\n",
    "    .agg({'products': 'count'}) \\\n",
    "    .rename(columns={'products': 'purchase_count'}) \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns={'products': 'productId'})\n",
    "data['productId'] = data['productId'].astype(np.int64)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Create dummy\n",
    "\n",
    "Dummy for marking whether a customer bought that item or not.\n",
    "If one buys an item, then purchase_dummy are marked as 1\n",
    "Why create a dummy instead of normalizing it, you ask?\n",
    "Normalizing the purchase count, say by each user, would not work because customers may have different buying frequency don't have the same taste\n",
    "However, we can normalize items by purchase frequency across all users, which is done below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_dummy(data):\n",
    "    data_dummy = data.copy()\n",
    "    data_dummy['purchase_dummy'] = 1\n",
    "    return data_dummy\n",
    "data_dummy = create_data_dummy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Normalize item values across users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = pd.pivot_table(data, values='purchase_count', index='customerId', columns='productId')\n",
    "df_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix_norm = (df_matrix-df_matrix.min())/(df_matrix.max()-df_matrix.min())\n",
    "print(df_matrix_norm.shape)\n",
    "df_matrix_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table for input to the modeling\n",
    "\n",
    "d = df_matrix_norm.reset_index()\n",
    "d.index.names = ['scaled_purchase_freq']\n",
    "data_norm = pd.melt(d, id_vars=['customerId'], value_name='scaled_purchase_freq').dropna()\n",
    "print(data_norm.shape)\n",
    "data_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Preparing data for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_idxs = np.array(data_norm.customerId, dtype = np.int)\n",
    "product_idxs = np.array(data_norm.productId, dtype = np.int)\n",
    "\n",
    "ratings = np.array(data_norm.scaled_purchase_freq)\n",
    "\n",
    "n_customers = int(data_norm['customerId'].drop_duplicates().max()) + 1\n",
    "n_products = int(data_norm['productId'].drop_duplicates().max()) + 1\n",
    "n_factors = 50\n",
    "\n",
    "input_shape = (1,)\n",
    "\n",
    "print(n_customers)\n",
    "print(n_products)\n",
    "print(customer_idxs)\n",
    "print(product_idxs)\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Tensorflow Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TF session and set it in Keras\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepCollaborativeFiltering(Model):\n",
    "    def __init__(self, n_customers, n_products, n_factors, p_dropout = 0.2):\n",
    "        x1 = Input(shape = (1,), name=\"user\")\n",
    "\n",
    "        P = Embedding(n_customers, n_factors, input_length = 1)(x1)\n",
    "        P = Reshape((n_factors,))(P)\n",
    "\n",
    "        x2 = Input(shape = (1,), name=\"product\")\n",
    "\n",
    "        Q = Embedding(n_products, n_factors, input_length = 1)(x2)\n",
    "        Q = Reshape((n_factors,))(Q)\n",
    "\n",
    "        x = concatenate([P, Q], axis=1)\n",
    "        x = Dropout(p_dropout)(x)\n",
    "\n",
    "        x = Dense(n_factors)(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dropout(p_dropout)(x)\n",
    "\n",
    "        output = Dense(1)(x)       \n",
    "        \n",
    "        super(DeepCollaborativeFiltering, self).__init__([x1, x2], output)\n",
    "    \n",
    "    def rate(self, customer_idxs, product_idxs):\n",
    "        if (type(customer_idxs) == int and type(product_idxs) == int):\n",
    "            return self.predict([np.array(customer_idxs).reshape((1,)), np.array(product_idxs).reshape((1,))])\n",
    "        \n",
    "        if (type(customer_idxs) == str and type(product_idxs) == str):\n",
    "            return self.predict([np.array(customerMapping[customer_idxs]).reshape((1,)), np.array(productMapping[product_idxs]).reshape((1,))])\n",
    "        \n",
    "        return self.predict([\n",
    "            np.array([customerMapping[customer_idx] for customer_idx in customer_idxs]), \n",
    "            np.array([productMapping[product_idx] for product_idx in product_idxs])\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "val_per = 0.25\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepCollaborativeFiltering(n_customers, n_products, n_factors)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = mean_squared_logarithmic_error)\n",
    "model.fit(x = [customer_idxs, product_idxs], y = ratings, batch_size = bs, epochs = epochs, validation_split = val_per)\n",
    "print('Done training!')\n",
    "\n",
    "print (\"input 0\", model.input[0].name)\n",
    "print (\"input 1\", model.input[1].name)\n",
    "print (\"input \", model.input)\n",
    "\n",
    "print (\"output 0\", model.output[0].name)\n",
    "print (\"output 1\", model.output[1].name)\n",
    "print (\"output\", model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Get current output directory for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorystream = minioClient.get_object('data', 'recommender/directory.txt')\n",
    "directory = \"\"\n",
    "for d in directorystream.stream(32*1024):\n",
    "    directory += d.decode('utf-8')\n",
    "arg_version = \"1\"    \n",
    "export_path = 's3://models/' + directory + '/' + arg_version + '/'\n",
    "print ('Exporting trained model to', export_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Export models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_info_ver = tf.saved_model.utils.build_tensor_info(tf.constant([arg_version]))\n",
    "# inputs/outputs\n",
    "tensor_info_users = tf.saved_model.utils.build_tensor_info(model.input[0])\n",
    "tensor_info_products = tf.saved_model.utils.build_tensor_info(model.input[1])\n",
    "tensor_info_pred = tf.saved_model.utils.build_tensor_info(model.output)\n",
    "# signature\n",
    "prediction_signature = (tf.saved_model.signature_def_utils.build_signature_def(\n",
    "        inputs={'users': tensor_info_users, 'products': tensor_info_products},\n",
    "        outputs={'recommendations': tensor_info_pred,\n",
    "                 'model-version': tensor_info_ver},\n",
    "        method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "# export\n",
    "legacy_init_op = tf.group(tf.tables_initializer(), name='legacy_init_op')\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "           tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY: prediction_signature,\n",
    "      },\n",
    "      legacy_init_op=legacy_init_op)\n",
    "builder.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
